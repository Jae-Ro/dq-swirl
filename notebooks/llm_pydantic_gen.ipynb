{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ebfeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaero/projects/interviews/team_raft/dq-swirl/.venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from typing import List, Optional\n",
    "\n",
    "import tqdm as notebook_tqdm\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field, constr, field_validator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import logging as transformers_logging\n",
    "\n",
    "from dq_swirl.clients.async_llm_client import AsyncLLMClient\n",
    "from dq_swirl.ingestion.structure_analyzer import StructuralAnalyzer\n",
    "from dq_swirl.rust_ingestion import smart_parse_batch\n",
    "\n",
    "transformers_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6168d974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"../secrets.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d067ba83",
   "metadata": {},
   "source": [
    "## Messy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9549bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data = [\n",
    "    \"Order 1001: Buyer=John Davis, Location=Columbus, OH, Total=$742.10, Items: laptop, hdmi cable\",\n",
    "    \"Order 1004:   Buyer=  AMANDA SMITH ,Location=Seattle, WA,Total=$50.00, Items: desk lamp\",\n",
    "    \"Order 1005: Buyer=Raj Patel, Total=1,200.50, Items: monitor, stand, cable\",\n",
    "    \"Order 1006: total=$89.99, location=Miami, FL, buyer=Elena Rossi, Items: keyboard\",\n",
    "    \"Order 1007: Buyer=Chris P., Location=Denver, CO, Total=$12.00, Items: stickers -- [DISCOUNT APPLIED]\",\n",
    "    \"Order 1008: Buyer=O'Connor, S., Location=Portland, OR, Total=$0.00, Items: \",\n",
    "    \"Order 1011: Buyer=John Davis, Location=Columbus, OH, Total=$742.10, Items: laptop, hdmi cable\",\n",
    "    \"Order 1012: Buyer=Sarah Liu, Location=Austin, TX, Total=$156.55, Items: headphones\",\n",
    "    \"Order 1013: Buyer=Mike Turner, Location=Cleveland, OH, Total=$1299.99, Items: gaming pc, mouse\",\n",
    "    \"Order 1014: Buyer=Rachel Kim, Locadtion=Seattle, WA, Total=$89.50, Items: coffee maker\",\n",
    "    \"Order 1015: Buyer=Chris Myers, Location=Cincinnati, OH, Total=$512.00, Items: monitor, desk lamp\",\n",
    "    \"Order=1016, Buyer=Jake Myers, Total=$1,512.00, Items: monitor,\",\n",
    "    \"Maples=Tree, Name:  Jae\",\n",
    "    '{\"id\": \"usr_001\", \"name\": \"Alex Johnson\", \"role\": \"admin\", \"isActive\": true, \"createdAt\": \"2025-11-02T09:14:23Z\"}',\n",
    "    '{\"id\": \"usr_002\", \"name\": \"Maria Lopez\", \"email\": \"maria.lopez@example.com\", \"role\": \"editor\", \"isActive\": null, \"createdAt\": \"2025-12-18T16:47:10Z\", \"lastLoginIp\": \"192.168.1.42\"}',\n",
    "    '{\"id\": \"usr_003\", \"email\": \"samir.patel@example.com\", \"role\": \"viewer\", \"isActive\": false, \"createdAt\": \"08/05/2024\"}',\n",
    "    '{\"id\": 4, \"name\": \"Chen Wei\", \"email\": \"chen.wei@example.com\", \"isActive\": true, \"createdAt\": null}',\n",
    "    '{\"id\": \"usr_005\", \"name\": \"Broken Record\", \"email\": \"broken@example.com\"}',\n",
    "    \"name =Sam, hobby = computers, id=1\",\n",
    "    \"name=Sam, hobby=computers, id=1\",\n",
    "    \"name = Sam, hobby = computers, id = 1\",\n",
    "    \"version: 3, product: software\",\n",
    "    # '{\"user\":{\"id\":123,\"name\":\"Alice\",\"profile\":{\"age\":30,\"hobbies\":[\"reading\",\"cycling\",\"coding\"],\"address\":{\"street\":\"123 Main St\",\"city\":\"Metropolis\",\"zip\":\"12345\"}}},\"orders\":[{\"order_id\":1001,\"items\":[\"book\",\"pen\"],\"total\":25.5},{\"order_id\":1002,\"items\":[\"laptop\"],\"total\":1200.0}],\"active\":true}',\n",
    "    \"Order 1017: Buyer=Chris Myers, Location=Columbia, SC, Total=$512.00, Items: monitor, desk lamp, Discount: yes\",\n",
    "    \"2026-01-30 14:22:01 INFO User login successful user_id=123\",\n",
    "    \"2026-01-30 14:22:01 INFO User login successful\",\n",
    "    \"level =INFO, user =Sam, id=1\",\n",
    "    \"timestamp=2026-01-30T14:22:01Z level=INFO user=alice action=login success=true\",\n",
    "    \"level=INFO cpu_usage=1,234.56 memory=512MB\",\n",
    "    '{\"level\":\"INFO\",\"service\":\"orders\",\"order_id\":1001,\"status\":\"created\"}',\n",
    "    '[2026-01-31 17:11:22 +0000] [7] [INFO] 127.0.0.1:56718 - - [31/Jan/2026:17:11:22 +0000] \"GET /health 1.1\" 200 16 \"-\" \"curl/8.14.1\"',\n",
    "    \"2026-01-31 17:11:00 swirl [DEBUG] saq_worker.py:28 Running cron job health check\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d865678",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be705a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UNSTRUCTURED STRING SAMPLES: 25\n",
      "\n",
      "JSON STRING SAMPLES: 6\n",
      "\n",
      "Original: Order 1001: Buyer=John Davis, Location=Columbus, OH, Total=$742.10, Items: laptop, hdmi cable\n",
      "Parsed: {'Order': '1001', 'Buyer': 'John Davis', 'Location': 'Columbus, OH', 'Total': '$742.10', 'Items': 'laptop, hdmi cable'}\n",
      "\n",
      "Original: Order 1004:   Buyer=  AMANDA SMITH ,Location=Seattle, WA,Total=$50.00, Items: desk lamp\n",
      "Parsed: {'Order': '1004', 'Buyer': 'AMANDA SMITH', 'Location': 'Seattle, WA', 'Total': '$50.00', 'Items': 'desk lamp'}\n",
      "\n",
      "Original: Order 1005: Buyer=Raj Patel, Total=1,200.50, Items: monitor, stand, cable\n",
      "Parsed: {'Order': '1005', 'Buyer': 'Raj Patel', 'Total': '1,200.50', 'Items': 'monitor, stand, cable'}\n",
      "\n",
      "Original: Order 1006: total=$89.99, location=Miami, FL, buyer=Elena Rossi, Items: keyboard\n",
      "Parsed: {'Order': '1006', 'total': '$89.99', 'location': 'Miami, FL', 'buyer': 'Elena Rossi', 'Items': 'keyboard'}\n",
      "\n",
      "Original: Order 1007: Buyer=Chris P., Location=Denver, CO, Total=$12.00, Items: stickers -- [DISCOUNT APPLIED]\n",
      "Parsed: {'Order': '1007', 'Buyer': 'Chris P.', 'Location': 'Denver, CO', 'Total': '$12.00', 'Items': 'stickers -- [DISCOUNT APPLIED]'}\n",
      "\n",
      "Original: Order 1008: Buyer=O'Connor, S., Location=Portland, OR, Total=$0.00, Items: \n",
      "Parsed: {'Order': '1008', 'Buyer': \"O'Connor, S.\", 'Location': 'Portland, OR', 'Total': '$0.00', 'Items': 'None'}\n",
      "\n",
      "Original: Order 1011: Buyer=John Davis, Location=Columbus, OH, Total=$742.10, Items: laptop, hdmi cable\n",
      "Parsed: {'Order': '1011', 'Buyer': 'John Davis', 'Location': 'Columbus, OH', 'Total': '$742.10', 'Items': 'laptop, hdmi cable'}\n",
      "\n",
      "Original: Order 1012: Buyer=Sarah Liu, Location=Austin, TX, Total=$156.55, Items: headphones\n",
      "Parsed: {'Order': '1012', 'Buyer': 'Sarah Liu', 'Location': 'Austin, TX', 'Total': '$156.55', 'Items': 'headphones'}\n",
      "\n",
      "Original: Order 1013: Buyer=Mike Turner, Location=Cleveland, OH, Total=$1299.99, Items: gaming pc, mouse\n",
      "Parsed: {'Order': '1013', 'Buyer': 'Mike Turner', 'Location': 'Cleveland, OH', 'Total': '$1299.99', 'Items': 'gaming pc, mouse'}\n",
      "\n",
      "Original: Order 1014: Buyer=Rachel Kim, Locadtion=Seattle, WA, Total=$89.50, Items: coffee maker\n",
      "Parsed: {'Order': '1014', 'Buyer': 'Rachel Kim', 'Locadtion': 'Seattle, WA', 'Total': '$89.50', 'Items': 'coffee maker'}\n",
      "\n",
      "Original: Order 1015: Buyer=Chris Myers, Location=Cincinnati, OH, Total=$512.00, Items: monitor, desk lamp\n",
      "Parsed: {'Order': '1015', 'Buyer': 'Chris Myers', 'Location': 'Cincinnati, OH', 'Total': '$512.00', 'Items': 'monitor, desk lamp'}\n",
      "\n",
      "Original: Order=1016, Buyer=Jake Myers, Total=$1,512.00, Items: monitor,\n",
      "Parsed: {'Order': '1016', 'Buyer': 'Jake Myers', 'Total': '$1,512.00', 'Items': 'monitor'}\n",
      "\n",
      "Original: Maples=Tree, Name:  Jae\n",
      "Parsed: {'Maples': 'Tree', 'Name': 'Jae'}\n",
      "\n",
      "Original: name =Sam, hobby = computers, id=1\n",
      "Parsed: {'name': 'Sam', 'hobby': 'computers', 'id': '1'}\n",
      "\n",
      "Original: name=Sam, hobby=computers, id=1\n",
      "Parsed: {'name': 'Sam', 'hobby': 'computers', 'id': '1'}\n",
      "\n",
      "Original: name = Sam, hobby = computers, id = 1\n",
      "Parsed: {'name': 'Sam', 'hobby': 'computers', 'id': '1'}\n",
      "\n",
      "Original: version: 3, product: software\n",
      "Parsed: {'version': '3', 'product': 'software'}\n",
      "\n",
      "Original: Order 1017: Buyer=Chris Myers, Location=Columbia, SC, Total=$512.00, Items: monitor, desk lamp, Discount: yes\n",
      "Parsed: {'Order': '1017', 'Buyer': 'Chris Myers', 'Location': 'Columbia, SC', 'Total': '$512.00', 'Items': 'monitor, desk lamp', 'Discount': 'yes'}\n",
      "\n",
      "Original: 2026-01-30 14:22:01 INFO User login successful user_id=123\n",
      "Parsed: {'user_id': '123', '_unparsed': '2026-01-30 14:22:01 INFO User login successful'}\n",
      "\n",
      "Original: 2026-01-30 14:22:01 INFO User login successful\n",
      "Parsed: {'_unparsed': '2026-01-30 14:22:01 INFO User login successful'}\n",
      "\n",
      "Original: level =INFO, user =Sam, id=1\n",
      "Parsed: {'level': 'INFO', 'user': 'Sam', 'id': '1'}\n",
      "\n",
      "Original: timestamp=2026-01-30T14:22:01Z level=INFO user=alice action=login success=true\n",
      "Parsed: {'timestamp': '2026-01-30T14:22:01Z', 'level': 'INFO', 'user': 'alice', 'action': 'login', 'success': 'true'}\n",
      "\n",
      "Original: level=INFO cpu_usage=1,234.56 memory=512MB\n",
      "Parsed: {'level': 'INFO', 'cpu_usage': '1,234.56', 'memory': '512MB'}\n",
      "\n",
      "Original: [2026-01-31 17:11:22 +0000] [7] [INFO] 127.0.0.1:56718 - - [31/Jan/2026:17:11:22 +0000] \"GET /health 1.1\" 200 16 \"-\" \"curl/8.14.1\"\n",
      "Parsed: {'_unparsed': '[2026-01-31 17:11:22 +0000] [7] [INFO] 127.0.0.1:56718 - - [31/Jan/2026:17:11:22 +0000] \"GET /health 1.1\" 200 16 \"-\" \"curl/8.14.1\"'}\n",
      "\n",
      "Original: 2026-01-31 17:11:00 swirl [DEBUG] saq_worker.py:28 Running cron job health check\n",
      "Parsed: {'_unparsed': '2026-01-31 17:11:00 swirl [DEBUG] saq_worker.py:28 Running cron job health check'}\n",
      "\n",
      "\n",
      "TOTAL SAMPLES: 31\n",
      "ERROR SAMPLES: 0\n",
      "\n",
      "Detected 18 unique schemas across 31 records.\n",
      "\n",
      "Schema 28d9f3b14d0e5516a186062212502d0c (1 occurrences):\n",
      "  Layout: {'order': 'str', 'buyer': 'str', 'locadtion': 'str', 'total': 'str', 'items': 'str'}\n",
      "------------------------------\n",
      "Schema 2bcfb738a2056c5ef5543917c9f3ac53 (1 occurrences):\n",
      "  Layout: {'id': 'int', 'name': 'str', 'email': 'str', 'isactive': 'bool', 'createdat': 'NoneType'}\n",
      "------------------------------\n",
      "Schema 3340e11ee417dd9f9cab0fd70836ccb4 (3 occurrences):\n",
      "  Layout: {'name': 'str', 'hobby': 'str', 'id': 'str'}\n",
      "------------------------------\n",
      "Schema 3baae1f59cac077e89e2f0b7d47a36cf (1 occurrences):\n",
      "  Layout: {'user_id': 'str', '_unparsed': 'str'}\n",
      "------------------------------\n",
      "Schema 4286ed8928a42e13682233f00079d106 (1 occurrences):\n",
      "  Layout: {'id': 'str', 'name': 'str', 'email': 'str', 'role': 'str', 'isactive': 'NoneType', 'createdat': 'str', 'lastloginip': 'str'}\n",
      "------------------------------\n",
      "Schema 461a895ef9c5046dd2cb5026b6a62de0 (1 occurrences):\n",
      "  Layout: {'order': 'str', 'buyer': 'str', 'location': 'str', 'total': 'str', 'items': 'str', 'discount': 'str'}\n",
      "------------------------------\n",
      "Schema 50eb97a85647221ecc7f65f74d68d156 (2 occurrences):\n",
      "  Layout: {'order': 'str', 'buyer': 'str', 'total': 'str', 'items': 'str'}\n",
      "------------------------------\n",
      "Schema 6f2b720d18e351508e6a8b520ae97f92 (1 occurrences):\n",
      "  Layout: {'maples': 'str', 'name': 'str'}\n",
      "------------------------------\n",
      "Schema 74db6b18a3e440d4dd054614492fa510 (1 occurrences):\n",
      "  Layout: {'timestamp': 'str', 'level': 'str', 'user': 'str', 'action': 'str', 'success': 'str'}\n",
      "------------------------------\n",
      "Schema a0713c61038426204fef9da85c91686f (1 occurrences):\n",
      "  Layout: {'id': 'str', 'name': 'str', 'role': 'str', 'isactive': 'bool', 'createdat': 'str'}\n",
      "------------------------------\n",
      "Schema c2aebc126ff252eb9dae084d659d2cab (1 occurrences):\n",
      "  Layout: {'level': 'str', 'user': 'str', 'id': 'str'}\n",
      "------------------------------\n",
      "Schema ce59f3f30262af34c2a4b11cec9950dd (1 occurrences):\n",
      "  Layout: {'version': 'str', 'product': 'str'}\n",
      "------------------------------\n",
      "Schema d0f1c5f0782666cd8324b4cf57a3159d (1 occurrences):\n",
      "  Layout: {'level': 'str', 'cpu_usage': 'str', 'memory': 'str'}\n",
      "------------------------------\n",
      "Schema d2d16f7c3698c6195ddaeb6205139150 (1 occurrences):\n",
      "  Layout: {'id': 'str', 'name': 'str', 'email': 'str'}\n",
      "------------------------------\n",
      "Schema d5d811706d95e2f6c1b713aa3fd1d9ab (1 occurrences):\n",
      "  Layout: {'id': 'str', 'email': 'str', 'role': 'str', 'isactive': 'bool', 'createdat': 'str'}\n",
      "------------------------------\n",
      "Schema df87355cb94200d773396f5befa867d4 (3 occurrences):\n",
      "  Layout: {'_unparsed': 'str'}\n",
      "------------------------------\n",
      "Schema e8b13b0b419896ad0f402c15a762e2c1 (1 occurrences):\n",
      "  Layout: {'level': 'str', 'service': 'str', 'order_id': 'int', 'status': 'str'}\n",
      "------------------------------\n",
      "Schema fd116cd512d5ecd2e59edf12fc258b32 (9 occurrences):\n",
      "  Layout: {'order': 'str', 'buyer': 'str', 'location': 'str', 'total': 'str', 'items': 'str'}\n",
      "------------------------------\n",
      "Structural Clusters: \n",
      "{\n",
      "    \"1\": [\n",
      "        {\n",
      "            \"signature_hash\": \"28d9f3b14d0e5516a186062212502d0c\",\n",
      "            \"fields\": [\n",
      "                \"order\",\n",
      "                \"buyer\",\n",
      "                \"locadtion\",\n",
      "                \"total\",\n",
      "                \"items\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"461a895ef9c5046dd2cb5026b6a62de0\",\n",
      "            \"fields\": [\n",
      "                \"order\",\n",
      "                \"buyer\",\n",
      "                \"location\",\n",
      "                \"total\",\n",
      "                \"items\",\n",
      "                \"discount\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"50eb97a85647221ecc7f65f74d68d156\",\n",
      "            \"fields\": [\n",
      "                \"order\",\n",
      "                \"buyer\",\n",
      "                \"total\",\n",
      "                \"items\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"fd116cd512d5ecd2e59edf12fc258b32\",\n",
      "            \"fields\": [\n",
      "                \"order\",\n",
      "                \"buyer\",\n",
      "                \"location\",\n",
      "                \"total\",\n",
      "                \"items\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        }\n",
      "    ],\n",
      "    \"0\": [\n",
      "        {\n",
      "            \"signature_hash\": \"2bcfb738a2056c5ef5543917c9f3ac53\",\n",
      "            \"fields\": [\n",
      "                \"id\",\n",
      "                \"name\",\n",
      "                \"email\",\n",
      "                \"isactive\",\n",
      "                \"createdat\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"3340e11ee417dd9f9cab0fd70836ccb4\",\n",
      "            \"fields\": [\n",
      "                \"name\",\n",
      "                \"hobby\",\n",
      "                \"id\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"4286ed8928a42e13682233f00079d106\",\n",
      "            \"fields\": [\n",
      "                \"id\",\n",
      "                \"name\",\n",
      "                \"email\",\n",
      "                \"role\",\n",
      "                \"isactive\",\n",
      "                \"createdat\",\n",
      "                \"lastloginip\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"6f2b720d18e351508e6a8b520ae97f92\",\n",
      "            \"fields\": [\n",
      "                \"maples\",\n",
      "                \"name\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"a0713c61038426204fef9da85c91686f\",\n",
      "            \"fields\": [\n",
      "                \"id\",\n",
      "                \"name\",\n",
      "                \"role\",\n",
      "                \"isactive\",\n",
      "                \"createdat\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"d2d16f7c3698c6195ddaeb6205139150\",\n",
      "            \"fields\": [\n",
      "                \"id\",\n",
      "                \"name\",\n",
      "                \"email\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"d5d811706d95e2f6c1b713aa3fd1d9ab\",\n",
      "            \"fields\": [\n",
      "                \"id\",\n",
      "                \"email\",\n",
      "                \"role\",\n",
      "                \"isactive\",\n",
      "                \"createdat\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        }\n",
      "    ],\n",
      "    \"3\": [\n",
      "        {\n",
      "            \"signature_hash\": \"3baae1f59cac077e89e2f0b7d47a36cf\",\n",
      "            \"fields\": [\n",
      "                \"user_id\",\n",
      "                \"_unparsed\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"df87355cb94200d773396f5befa867d4\",\n",
      "            \"fields\": [\n",
      "                \"_unparsed\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"e8b13b0b419896ad0f402c15a762e2c1\",\n",
      "            \"fields\": [\n",
      "                \"level\",\n",
      "                \"service\",\n",
      "                \"order_id\",\n",
      "                \"status\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        }\n",
      "    ],\n",
      "    \"2\": [\n",
      "        {\n",
      "            \"signature_hash\": \"74db6b18a3e440d4dd054614492fa510\",\n",
      "            \"fields\": [\n",
      "                \"timestamp\",\n",
      "                \"level\",\n",
      "                \"user\",\n",
      "                \"action\",\n",
      "                \"success\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"c2aebc126ff252eb9dae084d659d2cab\",\n",
      "            \"fields\": [\n",
      "                \"level\",\n",
      "                \"user\",\n",
      "                \"id\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"d0f1c5f0782666cd8324b4cf57a3159d\",\n",
      "            \"fields\": [\n",
      "                \"level\",\n",
      "                \"cpu_usage\",\n",
      "                \"memory\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        }\n",
      "    ],\n",
      "    \"-1\": [\n",
      "        {\n",
      "            \"signature_hash\": \"ce59f3f30262af34c2a4b11cec9950dd\",\n",
      "            \"fields\": [\n",
      "                \"version\",\n",
      "                \"product\"\n",
      "            ],\n",
      "            \"is_outlier\": true\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 958.94it/s, Materializing param=pooler.dense.weight]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Clusters: \n",
      "{\n",
      "    \"1\": [\n",
      "        {\n",
      "            \"signature_hash\": \"28d9f3b14d0e5516a186062212502d0c\",\n",
      "            \"fields\": [\n",
      "                \"order\",\n",
      "                \"buyer\",\n",
      "                \"locadtion\",\n",
      "                \"total\",\n",
      "                \"items\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"461a895ef9c5046dd2cb5026b6a62de0\",\n",
      "            \"fields\": [\n",
      "                \"order\",\n",
      "                \"buyer\",\n",
      "                \"location\",\n",
      "                \"total\",\n",
      "                \"items\",\n",
      "                \"discount\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"50eb97a85647221ecc7f65f74d68d156\",\n",
      "            \"fields\": [\n",
      "                \"order\",\n",
      "                \"buyer\",\n",
      "                \"total\",\n",
      "                \"items\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"fd116cd512d5ecd2e59edf12fc258b32\",\n",
      "            \"fields\": [\n",
      "                \"order\",\n",
      "                \"buyer\",\n",
      "                \"location\",\n",
      "                \"total\",\n",
      "                \"items\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        }\n",
      "    ],\n",
      "    \"3\": [\n",
      "        {\n",
      "            \"signature_hash\": \"2bcfb738a2056c5ef5543917c9f3ac53\",\n",
      "            \"fields\": [\n",
      "                \"id\",\n",
      "                \"name\",\n",
      "                \"email\",\n",
      "                \"isactive\",\n",
      "                \"createdat\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"4286ed8928a42e13682233f00079d106\",\n",
      "            \"fields\": [\n",
      "                \"id\",\n",
      "                \"name\",\n",
      "                \"email\",\n",
      "                \"role\",\n",
      "                \"isactive\",\n",
      "                \"createdat\",\n",
      "                \"lastloginip\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"a0713c61038426204fef9da85c91686f\",\n",
      "            \"fields\": [\n",
      "                \"id\",\n",
      "                \"name\",\n",
      "                \"role\",\n",
      "                \"isactive\",\n",
      "                \"createdat\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"d2d16f7c3698c6195ddaeb6205139150\",\n",
      "            \"fields\": [\n",
      "                \"id\",\n",
      "                \"name\",\n",
      "                \"email\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"d5d811706d95e2f6c1b713aa3fd1d9ab\",\n",
      "            \"fields\": [\n",
      "                \"id\",\n",
      "                \"email\",\n",
      "                \"role\",\n",
      "                \"isactive\",\n",
      "                \"createdat\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        }\n",
      "    ],\n",
      "    \"-1\": [\n",
      "        {\n",
      "            \"signature_hash\": \"3340e11ee417dd9f9cab0fd70836ccb4\",\n",
      "            \"fields\": [\n",
      "                \"name\",\n",
      "                \"hobby\",\n",
      "                \"id\"\n",
      "            ],\n",
      "            \"is_outlier\": true\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"6f2b720d18e351508e6a8b520ae97f92\",\n",
      "            \"fields\": [\n",
      "                \"maples\",\n",
      "                \"name\"\n",
      "            ],\n",
      "            \"is_outlier\": true\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"74db6b18a3e440d4dd054614492fa510\",\n",
      "            \"fields\": [\n",
      "                \"timestamp\",\n",
      "                \"level\",\n",
      "                \"user\",\n",
      "                \"action\",\n",
      "                \"success\"\n",
      "            ],\n",
      "            \"is_outlier\": true\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"d0f1c5f0782666cd8324b4cf57a3159d\",\n",
      "            \"fields\": [\n",
      "                \"level\",\n",
      "                \"cpu_usage\",\n",
      "                \"memory\"\n",
      "            ],\n",
      "            \"is_outlier\": true\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"e8b13b0b419896ad0f402c15a762e2c1\",\n",
      "            \"fields\": [\n",
      "                \"level\",\n",
      "                \"service\",\n",
      "                \"order_id\",\n",
      "                \"status\"\n",
      "            ],\n",
      "            \"is_outlier\": true\n",
      "        }\n",
      "    ],\n",
      "    \"2\": [\n",
      "        {\n",
      "            \"signature_hash\": \"3baae1f59cac077e89e2f0b7d47a36cf\",\n",
      "            \"fields\": [\n",
      "                \"user_id\",\n",
      "                \"_unparsed\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"c2aebc126ff252eb9dae084d659d2cab\",\n",
      "            \"fields\": [\n",
      "                \"level\",\n",
      "                \"user\",\n",
      "                \"id\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        }\n",
      "    ],\n",
      "    \"0\": [\n",
      "        {\n",
      "            \"signature_hash\": \"ce59f3f30262af34c2a4b11cec9950dd\",\n",
      "            \"fields\": [\n",
      "                \"version\",\n",
      "                \"product\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        },\n",
      "        {\n",
      "            \"signature_hash\": \"df87355cb94200d773396f5befa867d4\",\n",
      "            \"fields\": [\n",
      "                \"_unparsed\"\n",
      "            ],\n",
      "            \"is_outlier\": false\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#################################################################################\n",
    "################################# Grammar Parsing ###############################\n",
    "#################################################################################\n",
    "\n",
    "string_batch = []\n",
    "string_json_batch = []\n",
    "for msg in messy_data:\n",
    "    if not (msg.startswith(\"[\") and msg.endswith(\"]\")) and not (\n",
    "        msg.startswith(\"{\") and msg.endswith(\"}\")\n",
    "    ):\n",
    "        string_batch.append(msg)\n",
    "    else:\n",
    "        string_json_batch.append(msg)\n",
    "\n",
    "print(f\"\\nUNSTRUCTURED STRING SAMPLES: {len(string_batch)}\\n\")\n",
    "print(f\"JSON STRING SAMPLES: {len(string_json_batch)}\\n\")\n",
    "\n",
    "\n",
    "string_samples = smart_parse_batch(string_batch)\n",
    "\n",
    "for i, (msg, parsed) in enumerate(string_samples):\n",
    "    print(f\"Original: {msg}\\nParsed: {parsed}\\n\")\n",
    "\n",
    "\n",
    "json_samples = []\n",
    "leftovers = []\n",
    "\n",
    "for msg in string_json_batch:\n",
    "    try:\n",
    "        data = json.loads(msg)\n",
    "        json_samples.append((msg, data))\n",
    "    except Exception:\n",
    "        leftovers.append((msg, None))\n",
    "\n",
    "\n",
    "data_samples = string_samples + json_samples\n",
    "\n",
    "print(f\"\\nTOTAL SAMPLES: {len(data_samples)}\\nERROR SAMPLES: {len(leftovers)}\\n\")\n",
    "\n",
    "#################################################################################\n",
    "############################### Structure Analyzer ##############################\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "analyzer = StructuralAnalyzer(ignore_unparsed=False)\n",
    "\n",
    "hash_counts = Counter()\n",
    "unique_structures = {}\n",
    "\n",
    "for raw, parsed in data_samples:\n",
    "    result = analyzer.generate_fingerprint(raw, parsed)\n",
    "    signature_hash = result[\"hash\"]\n",
    "    hash_counts[signature_hash] += 1\n",
    "    unique_structures[signature_hash] = unique_structures.get(signature_hash, result)\n",
    "\n",
    "print(\n",
    "    f\"Detected {len(unique_structures)} unique schemas across {len(data_samples)} records.\\n\"\n",
    ")\n",
    "\n",
    "for h, count in sorted(hash_counts.items()):\n",
    "    print(f\"Schema {h} ({count} occurrences):\")\n",
    "    print(f\"  Layout: {unique_structures[h]['signature']}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "############################# Structural Clustering #############################\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "def conjoin_signatures(registry_output: dict):\n",
    "    hashes = list(registry_output.keys())\n",
    "\n",
    "    signatures_as_text = [\n",
    "        \" \".join(registry_output[h][\"signature\"].keys()) for h in hashes\n",
    "    ]\n",
    "\n",
    "    vectorizer = TfidfVectorizer(analyzer=\"char\", ngram_range=(3, 5))\n",
    "    matrix = vectorizer.fit_transform(signatures_as_text)\n",
    "\n",
    "    clusterer = HDBSCAN(\n",
    "        min_cluster_size=2,\n",
    "        metric=\"euclidean\",\n",
    "        copy=True,\n",
    "    )\n",
    "    labels = clusterer.fit_predict(matrix.toarray())\n",
    "\n",
    "    conjoined_map = {}\n",
    "    for i, cluster_id in enumerate(labels):\n",
    "        h = hashes[i]\n",
    "        conjoined_map[h] = {\n",
    "            \"cluster_id\": int(cluster_id),\n",
    "            \"keys\": list(registry_output[h][\"signature\"].keys()),\n",
    "            \"is_outlier\": cluster_id == -1,\n",
    "        }\n",
    "\n",
    "    sorted_dict = dict(sorted(conjoined_map.items()))\n",
    "    return sorted_dict\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "############################## Semantic Clustering ##############################\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "def conjoin_signatures_semantic(\n",
    "    registry_output: dict,\n",
    "    embedding_model: str = \"all-MiniLM-L6-v2\",\n",
    "    cache_dir: str = \"./.models\",\n",
    "):\n",
    "    hashes = list(registry_output.keys())\n",
    "    registry_copy = deepcopy(registry_output)\n",
    "\n",
    "    signatures_as_text = []\n",
    "    for h in hashes:\n",
    "        h_dict = registry_copy[h][\"signature\"]\n",
    "        h_dict.pop(\"_unparsed\", None)\n",
    "        signatures_as_text.append(\", \".join(h_dict))\n",
    "\n",
    "    model = SentenceTransformer(embedding_model, cache_folder=cache_dir)\n",
    "    embeddings = model.encode(signatures_as_text)\n",
    "\n",
    "    clusterer = HDBSCAN(\n",
    "        min_cluster_size=2,\n",
    "        min_samples=1,\n",
    "        metric=\"cosine\",\n",
    "        cluster_selection_epsilon=0.18,\n",
    "        cluster_selection_method=\"eom\",\n",
    "        copy=True,\n",
    "    )\n",
    "    labels = clusterer.fit_predict(embeddings.astype(\"float64\"))\n",
    "\n",
    "    conjoined_map = {}\n",
    "    for i, cluster_id in enumerate(labels):\n",
    "        h = hashes[i]\n",
    "        conjoined_map[h] = {\n",
    "            \"cluster_id\": int(cluster_id),\n",
    "            \"keys\": list(registry_output[h][\"signature\"].keys()),\n",
    "            \"is_outlier\": cluster_id == -1,\n",
    "        }\n",
    "\n",
    "    return dict(sorted(conjoined_map.items()))\n",
    "\n",
    "\n",
    "# run structure clustering\n",
    "structure_cluster_map = conjoin_signatures(analyzer.signature_map)\n",
    "structure_clusters = {}\n",
    "for k, v in structure_cluster_map.items():\n",
    "    cluster_id = v[\"cluster_id\"]\n",
    "    keys = v[\"keys\"]\n",
    "    is_outlier = bool(v[\"is_outlier\"])\n",
    "    structure_clusters[cluster_id] = structure_clusters.get(cluster_id, [])\n",
    "    structure_clusters[cluster_id].append(\n",
    "        {\"signature_hash\": k, \"fields\": keys, \"is_outlier\": is_outlier}\n",
    "    )\n",
    "print(f\"Structural Clusters: \\n{json.dumps(structure_clusters, indent=4)}\\n\")\n",
    "\n",
    "\n",
    "# run semantic clustering\n",
    "semantic_cluster_map = conjoin_signatures_semantic(analyzer.signature_map)\n",
    "semantic_clusters = {}\n",
    "for k, v in semantic_cluster_map.items():\n",
    "    cluster_id = v[\"cluster_id\"]\n",
    "    keys = v[\"keys\"]\n",
    "    is_outlier = bool(v[\"is_outlier\"])\n",
    "    semantic_clusters[cluster_id] = semantic_clusters.get(cluster_id, [])\n",
    "    semantic_clusters[cluster_id].append(\n",
    "        {\"signature_hash\": k, \"fields\": keys, \"is_outlier\": is_outlier}\n",
    "    )\n",
    "print(f\"Semantic Clusters: \\n{json.dumps(semantic_clusters, indent=4)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb800c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [{'signature_hash': '28d9f3b14d0e5516a186062212502d0c',\n",
       "   'raw': 'Order 1014: Buyer=Rachel Kim, Locadtion=Seattle, WA, Total=$89.50, Items: coffee maker',\n",
       "   'parsed': {'Order': '1014',\n",
       "    'Buyer': 'Rachel Kim',\n",
       "    'Locadtion': 'Seattle, WA',\n",
       "    'Total': '$89.50',\n",
       "    'Items': 'coffee maker'}},\n",
       "  {'signature_hash': '461a895ef9c5046dd2cb5026b6a62de0',\n",
       "   'raw': 'Order 1017: Buyer=Chris Myers, Location=Columbia, SC, Total=$512.00, Items: monitor, desk lamp, Discount: yes',\n",
       "   'parsed': {'Order': '1017',\n",
       "    'Buyer': 'Chris Myers',\n",
       "    'Location': 'Columbia, SC',\n",
       "    'Total': '$512.00',\n",
       "    'Items': 'monitor, desk lamp',\n",
       "    'Discount': 'yes'}},\n",
       "  {'signature_hash': '50eb97a85647221ecc7f65f74d68d156',\n",
       "   'raw': 'Order 1005: Buyer=Raj Patel, Total=1,200.50, Items: monitor, stand, cable',\n",
       "   'parsed': {'Order': '1005',\n",
       "    'Buyer': 'Raj Patel',\n",
       "    'Total': '1,200.50',\n",
       "    'Items': 'monitor, stand, cable'}},\n",
       "  {'signature_hash': '50eb97a85647221ecc7f65f74d68d156',\n",
       "   'raw': 'Order=1016, Buyer=Jake Myers, Total=$1,512.00, Items: monitor,',\n",
       "   'parsed': {'Order': '1016',\n",
       "    'Buyer': 'Jake Myers',\n",
       "    'Total': '$1,512.00',\n",
       "    'Items': 'monitor'}},\n",
       "  {'signature_hash': 'fd116cd512d5ecd2e59edf12fc258b32',\n",
       "   'raw': 'Order 1001: Buyer=John Davis, Location=Columbus, OH, Total=$742.10, Items: laptop, hdmi cable',\n",
       "   'parsed': {'Order': '1001',\n",
       "    'Buyer': 'John Davis',\n",
       "    'Location': 'Columbus, OH',\n",
       "    'Total': '$742.10',\n",
       "    'Items': 'laptop, hdmi cable'}},\n",
       "  {'signature_hash': 'fd116cd512d5ecd2e59edf12fc258b32',\n",
       "   'raw': 'Order 1004:   Buyer=  AMANDA SMITH ,Location=Seattle, WA,Total=$50.00, Items: desk lamp',\n",
       "   'parsed': {'Order': '1004',\n",
       "    'Buyer': 'AMANDA SMITH',\n",
       "    'Location': 'Seattle, WA',\n",
       "    'Total': '$50.00',\n",
       "    'Items': 'desk lamp'}},\n",
       "  {'signature_hash': 'fd116cd512d5ecd2e59edf12fc258b32',\n",
       "   'raw': 'Order 1006: total=$89.99, location=Miami, FL, buyer=Elena Rossi, Items: keyboard',\n",
       "   'parsed': {'Order': '1006',\n",
       "    'total': '$89.99',\n",
       "    'location': 'Miami, FL',\n",
       "    'buyer': 'Elena Rossi',\n",
       "    'Items': 'keyboard'}},\n",
       "  {'signature_hash': 'fd116cd512d5ecd2e59edf12fc258b32',\n",
       "   'raw': 'Order 1007: Buyer=Chris P., Location=Denver, CO, Total=$12.00, Items: stickers -- [DISCOUNT APPLIED]',\n",
       "   'parsed': {'Order': '1007',\n",
       "    'Buyer': 'Chris P.',\n",
       "    'Location': 'Denver, CO',\n",
       "    'Total': '$12.00',\n",
       "    'Items': 'stickers -- [DISCOUNT APPLIED]'}},\n",
       "  {'signature_hash': 'fd116cd512d5ecd2e59edf12fc258b32',\n",
       "   'raw': \"Order 1008: Buyer=O'Connor, S., Location=Portland, OR, Total=$0.00, Items: \",\n",
       "   'parsed': {'Order': '1008',\n",
       "    'Buyer': \"O'Connor, S.\",\n",
       "    'Location': 'Portland, OR',\n",
       "    'Total': '$0.00',\n",
       "    'Items': 'None'}},\n",
       "  {'signature_hash': 'fd116cd512d5ecd2e59edf12fc258b32',\n",
       "   'raw': 'Order 1011: Buyer=John Davis, Location=Columbus, OH, Total=$742.10, Items: laptop, hdmi cable',\n",
       "   'parsed': {'Order': '1011',\n",
       "    'Buyer': 'John Davis',\n",
       "    'Location': 'Columbus, OH',\n",
       "    'Total': '$742.10',\n",
       "    'Items': 'laptop, hdmi cable'}},\n",
       "  {'signature_hash': 'fd116cd512d5ecd2e59edf12fc258b32',\n",
       "   'raw': 'Order 1012: Buyer=Sarah Liu, Location=Austin, TX, Total=$156.55, Items: headphones',\n",
       "   'parsed': {'Order': '1012',\n",
       "    'Buyer': 'Sarah Liu',\n",
       "    'Location': 'Austin, TX',\n",
       "    'Total': '$156.55',\n",
       "    'Items': 'headphones'}},\n",
       "  {'signature_hash': 'fd116cd512d5ecd2e59edf12fc258b32',\n",
       "   'raw': 'Order 1013: Buyer=Mike Turner, Location=Cleveland, OH, Total=$1299.99, Items: gaming pc, mouse',\n",
       "   'parsed': {'Order': '1013',\n",
       "    'Buyer': 'Mike Turner',\n",
       "    'Location': 'Cleveland, OH',\n",
       "    'Total': '$1299.99',\n",
       "    'Items': 'gaming pc, mouse'}},\n",
       "  {'signature_hash': 'fd116cd512d5ecd2e59edf12fc258b32',\n",
       "   'raw': 'Order 1015: Buyer=Chris Myers, Location=Cincinnati, OH, Total=$512.00, Items: monitor, desk lamp',\n",
       "   'parsed': {'Order': '1015',\n",
       "    'Buyer': 'Chris Myers',\n",
       "    'Location': 'Cincinnati, OH',\n",
       "    'Total': '$512.00',\n",
       "    'Items': 'monitor, desk lamp'}}],\n",
       " 3: [{'signature_hash': '2bcfb738a2056c5ef5543917c9f3ac53',\n",
       "   'raw': '{\"id\": 4, \"name\": \"Chen Wei\", \"email\": \"chen.wei@example.com\", \"isActive\": true, \"createdAt\": null}',\n",
       "   'parsed': {'id': 4,\n",
       "    'name': 'Chen Wei',\n",
       "    'email': 'chen.wei@example.com',\n",
       "    'isActive': True,\n",
       "    'createdAt': None}},\n",
       "  {'signature_hash': '4286ed8928a42e13682233f00079d106',\n",
       "   'raw': '{\"id\": \"usr_002\", \"name\": \"Maria Lopez\", \"email\": \"maria.lopez@example.com\", \"role\": \"editor\", \"isActive\": null, \"createdAt\": \"2025-12-18T16:47:10Z\", \"lastLoginIp\": \"192.168.1.42\"}',\n",
       "   'parsed': {'id': 'usr_002',\n",
       "    'name': 'Maria Lopez',\n",
       "    'email': 'maria.lopez@example.com',\n",
       "    'role': 'editor',\n",
       "    'isActive': None,\n",
       "    'createdAt': '2025-12-18T16:47:10Z',\n",
       "    'lastLoginIp': '192.168.1.42'}},\n",
       "  {'signature_hash': 'a0713c61038426204fef9da85c91686f',\n",
       "   'raw': '{\"id\": \"usr_001\", \"name\": \"Alex Johnson\", \"role\": \"admin\", \"isActive\": true, \"createdAt\": \"2025-11-02T09:14:23Z\"}',\n",
       "   'parsed': {'id': 'usr_001',\n",
       "    'name': 'Alex Johnson',\n",
       "    'role': 'admin',\n",
       "    'isActive': True,\n",
       "    'createdAt': '2025-11-02T09:14:23Z'}},\n",
       "  {'signature_hash': 'd2d16f7c3698c6195ddaeb6205139150',\n",
       "   'raw': '{\"id\": \"usr_005\", \"name\": \"Broken Record\", \"email\": \"broken@example.com\"}',\n",
       "   'parsed': {'id': 'usr_005',\n",
       "    'name': 'Broken Record',\n",
       "    'email': 'broken@example.com'}},\n",
       "  {'signature_hash': 'd5d811706d95e2f6c1b713aa3fd1d9ab',\n",
       "   'raw': '{\"id\": \"usr_003\", \"email\": \"samir.patel@example.com\", \"role\": \"viewer\", \"isActive\": false, \"createdAt\": \"08/05/2024\"}',\n",
       "   'parsed': {'id': 'usr_003',\n",
       "    'email': 'samir.patel@example.com',\n",
       "    'role': 'viewer',\n",
       "    'isActive': False,\n",
       "    'createdAt': '08/05/2024'}}],\n",
       " -1: [{'signature_hash': '3340e11ee417dd9f9cab0fd70836ccb4',\n",
       "   'raw': 'name =Sam, hobby = computers, id=1',\n",
       "   'parsed': {'name': 'Sam', 'hobby': 'computers', 'id': '1'}},\n",
       "  {'signature_hash': '3340e11ee417dd9f9cab0fd70836ccb4',\n",
       "   'raw': 'name=Sam, hobby=computers, id=1',\n",
       "   'parsed': {'name': 'Sam', 'hobby': 'computers', 'id': '1'}},\n",
       "  {'signature_hash': '3340e11ee417dd9f9cab0fd70836ccb4',\n",
       "   'raw': 'name = Sam, hobby = computers, id = 1',\n",
       "   'parsed': {'name': 'Sam', 'hobby': 'computers', 'id': '1'}},\n",
       "  {'signature_hash': '6f2b720d18e351508e6a8b520ae97f92',\n",
       "   'raw': 'Maples=Tree, Name:  Jae',\n",
       "   'parsed': {'Maples': 'Tree', 'Name': 'Jae'}},\n",
       "  {'signature_hash': '74db6b18a3e440d4dd054614492fa510',\n",
       "   'raw': 'timestamp=2026-01-30T14:22:01Z level=INFO user=alice action=login success=true',\n",
       "   'parsed': {'timestamp': '2026-01-30T14:22:01Z',\n",
       "    'level': 'INFO',\n",
       "    'user': 'alice',\n",
       "    'action': 'login',\n",
       "    'success': 'true'}},\n",
       "  {'signature_hash': 'd0f1c5f0782666cd8324b4cf57a3159d',\n",
       "   'raw': 'level=INFO cpu_usage=1,234.56 memory=512MB',\n",
       "   'parsed': {'level': 'INFO', 'cpu_usage': '1,234.56', 'memory': '512MB'}},\n",
       "  {'signature_hash': 'e8b13b0b419896ad0f402c15a762e2c1',\n",
       "   'raw': '{\"level\":\"INFO\",\"service\":\"orders\",\"order_id\":1001,\"status\":\"created\"}',\n",
       "   'parsed': {'level': 'INFO',\n",
       "    'service': 'orders',\n",
       "    'order_id': 1001,\n",
       "    'status': 'created'}}],\n",
       " 2: [{'signature_hash': '3baae1f59cac077e89e2f0b7d47a36cf',\n",
       "   'raw': '2026-01-30 14:22:01 INFO User login successful user_id=123',\n",
       "   'parsed': {'user_id': '123',\n",
       "    '_unparsed': '2026-01-30 14:22:01 INFO User login successful'}},\n",
       "  {'signature_hash': 'c2aebc126ff252eb9dae084d659d2cab',\n",
       "   'raw': 'level =INFO, user =Sam, id=1',\n",
       "   'parsed': {'level': 'INFO', 'user': 'Sam', 'id': '1'}}],\n",
       " 0: [{'signature_hash': 'ce59f3f30262af34c2a4b11cec9950dd',\n",
       "   'raw': 'version: 3, product: software',\n",
       "   'parsed': {'version': '3', 'product': 'software'}},\n",
       "  {'signature_hash': 'df87355cb94200d773396f5befa867d4',\n",
       "   'raw': '2026-01-30 14:22:01 INFO User login successful',\n",
       "   'parsed': {'_unparsed': '2026-01-30 14:22:01 INFO User login successful'}},\n",
       "  {'signature_hash': 'df87355cb94200d773396f5befa867d4',\n",
       "   'raw': '[2026-01-31 17:11:22 +0000] [7] [INFO] 127.0.0.1:56718 - - [31/Jan/2026:17:11:22 +0000] \"GET /health 1.1\" 200 16 \"-\" \"curl/8.14.1\"',\n",
       "   'parsed': {'_unparsed': '[2026-01-31 17:11:22 +0000] [7] [INFO] 127.0.0.1:56718 - - [31/Jan/2026:17:11:22 +0000] \"GET /health 1.1\" 200 16 \"-\" \"curl/8.14.1\"'}},\n",
       "  {'signature_hash': 'df87355cb94200d773396f5befa867d4',\n",
       "   'raw': '2026-01-31 17:11:00 swirl [DEBUG] saq_worker.py:28 Running cron job health check',\n",
       "   'parsed': {'_unparsed': '2026-01-31 17:11:00 swirl [DEBUG] saq_worker.py:28 Running cron job health check'}}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# semantic cluster map to raw strings\n",
    "cluster_dict = {}\n",
    "for cluster_id, records in semantic_clusters.items():\n",
    "    cluster_dict[cluster_id] = cluster_dict.get(cluster_id, [])\n",
    "    for rec in records:\n",
    "        signature_hash = rec[\"signature_hash\"]\n",
    "        analyzer_records = analyzer.signature_map[signature_hash][\"records\"]\n",
    "        for r in analyzer_records:\n",
    "            cluster_dict[cluster_id].append(\n",
    "                {\n",
    "                    \"signature_hash\": signature_hash,\n",
    "                    \"raw\": r[\"raw\"],\n",
    "                    \"parsed\": r[\"parsed\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "cluster_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70354b4f",
   "metadata": {},
   "source": [
    "## LLM Client Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f369b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm connection\n",
    "api_key = os.getenv(\"LLM_API_KEY\")\n",
    "# api_base_url = os.getenv(\"LLM_BASE_URL\")\n",
    "api_base_url = \"https://openrouter.ai/api/v1\"\n",
    "# model = \"openai/google/gemma-3-27b-it\"\n",
    "model = \"openai/gpt-oss-120b:exacto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cea7d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncLLMClient(\n",
    "    model,\n",
    "    api_base_url,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc455a6a",
   "metadata": {},
   "source": [
    "## LLM Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "760f05a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts\n",
    "PYDANTIC_SYSTEM_PROMPT = \"\"\"You are a Data Architect. Your goal is to perform unsupervised schema inference on a sample of unstructured data.\n",
    "\n",
    "Generate a Pydantic `BaseModel` class that represents the \"Gold Standard\" foundation for this data pattern. \n",
    "\n",
    "Instructions:\n",
    "- Normalization: Suggest clean, snake_case keys for the identified fields.\n",
    "- If you see a string value for a field that follows a consistent structure (e.g., \"<city>, <state>\") then make sure that structure is accurately typed in the BaseModel.\n",
    "- Determine what fields should be required vs optional based on overall semantic meaning of the entity you are creating a BaseModel class for.\n",
    "\n",
    "Constraints:\n",
    "- Include a detailed description for each field using the `Field` class to explain what the field is and if there are any expected structural patterns (e.g., `state` should be two letters).\n",
    "- Create supplemental BaseModel classes where necessary to preserve semantic clarity.\n",
    "- Do NOT include any regex.\n",
    "- If a field appears in some rows but not others, mark it as `Optional`.\n",
    "- You are only allowed to use the following imports: \"from typing import List, Dict, Optional; from pydantic import BaseModel, Field\".\n",
    "- Return ONLY the Pydantic class definitions (you are allowed to generate multiple as long as they are logically linked).\n",
    "\"\"\"\n",
    "\n",
    "PYDANTIC_USER_PROMPT = \"\"\"Please analyze the following representative samples of a new data pattern and generate the Pydantic 'Foundation' model.\n",
    "\n",
    "### Data Samples:\n",
    "{samples}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8c08fc",
   "metadata": {},
   "source": [
    "## Generate Pydantic BaseModel Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303d5e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"code_string\": \"from typing import List, Optional\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Location(BaseModel):\\n    \\\"\\\"\\\"Geographic location of the buyer.\\n    \\n    The location is represented as a city and a two‑letter US state abbreviation.\\n    \\\"\\\"\\\"\\n    city: str = Field(..., description=\\\"Name of the city where the buyer is located.\\\")\\n    state: str = Field(..., description=\\\"Two‑letter US state abbreviation (e.g., \\\\\\\"WA\\\\\\\", \\\\\\\"OH\\\\\\\").\\\")\\n\\n\\nclass Order(BaseModel):\\n    \\\"\\\"\\\"Representation of a single purchase order.\\n    \\n    Each order includes an identifier, buyer information, optional location, the monetary total,\\n    a list of purchased items, and an optional flag indicating whether a discount was applied.\\n    \\\"\\\"\\\"\\n    order_id: int = Field(..., description=\\\"Unique numeric identifier for the order.\\\")\\n    buyer: str = Field(..., description=\\\"Full name of the buyer as it appears in the source data.\\\")\\n    location: Optional[Location] = Field(\\n        None,\\n        description=\\\"Optional location object containing city and state. May be missing in some records.\\\"\\n    )\\n    total: float = Field(..., description=\\\"Total amount of the order in US dollars. Dollar sign and commas are stripped during parsing.\\\")\\n    items: List[str] = Field(\\n        default_factory=list,\\n        description=\\\"List of item names purchased. The list may be empty if no items are recorded.\\\"\\n    )\\n    discount_applied: Optional[bool] = Field(\\n        None,\\n        description=\\\"Flag indicating whether a discount was applied to the order. True when a discount marker is present; otherwise False or omitted.\\\"\\n    )\\n\",\n",
      "  \"entrypoint_class_name\": \"Order\"\n",
      "}\n",
      "Successfully wrote code to c1_order_base_model.py\n",
      "\n",
      "{\n",
      "  \"code_string\": \"from typing import Optional\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    id: str = Field(..., description=\\\"Unique identifier for the user; may be numeric or prefixed string such as 'usr_001'.\\\")\\n    name: Optional[str] = Field(None, description=\\\"Full name of the user.\\\")\\n    email: Optional[str] = Field(None, description=\\\"Email address of the user.\\\")\\n    role: Optional[str] = Field(None, description=\\\"User role within the system, e.g., 'admin', 'editor', 'viewer'.\\\")\\n    is_active: Optional[bool] = Field(None, description=\\\"Indicates whether the user account is currently active.\\\")\\n    created_at: Optional[str] = Field(None, description=\\\"Timestamp when the user was created; ISO 8601 format or date string.\\\")\\n    last_login_ip: Optional[str] = Field(None, description=\\\"IP address from which the user last logged in.\\\")\\n\",\n",
      "  \"entrypoint_class_name\": \"User\"\n",
      "}\n",
      "Successfully wrote code to c3_user_base_model.py\n",
      "\n",
      "{\n",
      "  \"code_string\": \"from typing import List, Dict, Optional\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass PersonInfo(BaseModel):\\n    \\\"\\\"\\\"Information about a person extracted from the record.\\\"\\\"\\\"\\n    name: Optional[str] = Field(\\n        None, description=\\\"Person's name.\\\"\\n    )\\n    hobby: Optional[str] = Field(\\n        None, description=\\\"Person's hobby.\\\"\\n    )\\n    id: Optional[int] = Field(\\n        None, description=\\\"Unique identifier for the person.\\\"\\n    )\\n\\n\\nclass SystemMetrics(BaseModel):\\n    \\\"\\\"\\\"Performance metrics that may appear in the data.\\\"\\\"\\\"\\n    cpu_usage: Optional[str] = Field(\\n        None,\\n        description=\\\"CPU usage, may include commas as thousand separator, e.g., '1,234.56'.\\\"\\n    )\\n    memory: Optional[str] = Field(\\n        None,\\n        description=\\\"Memory usage with unit, e.g., '512MB'.\\\"\\n    )\\n\\n\\nclass LogMetadata(BaseModel):\\n    \\\"\\\"\\\"Common log‑related fields found in the samples.\\\"\\\"\\\"\\n    timestamp: Optional[str] = Field(\\n        None,\\n        description=\\\"ISO‑8601 timestamp, e.g., '2026-01-30T14:22:01Z'.\\\"\\n    )\\n    level: Optional[str] = Field(\\n        None, description=\\\"Log level such as 'INFO', 'ERROR', etc.\\\"\\n    )\\n    user: Optional[str] = Field(\\n        None, description=\\\"Username associated with the log entry.\\\"\\n    )\\n    action: Optional[str] = Field(\\n        None, description=\\\"Action performed, e.g., 'login'.\\\"\\n    )\\n    success: Optional[bool] = Field(\\n        None, description=\\\"Indicates whether the action succeeded.\\\"\\n    )\\n\\n\\nclass OrderEvent(BaseModel):\\n    \\\"\\\"\\\"Fields that describe an order processing event.\\\"\\\"\\\"\\n    service: Optional[str] = Field(\\n        None, description=\\\"Name of the service handling the order.\\\"\\n    )\\n    order_id: Optional[int] = Field(\\n        None, description=\\\"Identifier of the order.\\\"\\n    )\\n    status: Optional[str] = Field(\\n        None, description=\\\"Current status of the order, e.g., 'created'.\\\"\\n    )\\n\\n\\nclass MiscKeyValue(BaseModel):\\n    \\\"\\\"\\\"Catch‑all for less common or ad‑hoc key/value pairs.\\\"\\\"\\\"\\n    maples: Optional[str] = Field(\\n        None, description=\\\"Value associated with the key 'Maples'.\\\"\\n    )\\n    extra: Optional[Dict[str, str]] = Field(\\n        default_factory=dict,\\n        description=\\\"Any additional key‑value pairs not explicitly modeled.\\\"\\n    )\\n\\n\\nclass Record(BaseModel):\\n    \\\"\\\"\\\"Gold‑standard foundation model that aggregates all discovered patterns.\\n\\n    Each sub‑model groups semantically related fields. All top‑level attributes are optional\\n    because the source data is heterogeneous and any given record may contain only a subset\\n    of the possible keys.\\n    \\\"\\\"\\\"\\n    person: Optional[PersonInfo] = Field(\\n        None, description=\\\"Person‑related information when present.\\\"\\n    )\\n    log: Optional[LogMetadata] = Field(\\n        None, description=\\\"Log metadata extracted from the record.\\\"\\n    )\\n    metrics: Optional[SystemMetrics] = Field(\\n        None, description=\\\"System performance metrics when available.\\\"\\n    )\\n    order: Optional[OrderEvent] = Field(\\n        None, description=\\\"Order‑related event data when present.\\\"\\n    )\\n    misc: Optional[MiscKeyValue] = Field(\\n        None, description=\\\"Miscellaneous key‑value pairs that do not fit other categories.\\\"\\n    )\\n    raw: Optional[Dict[str, str]] = Field(\\n        default_factory=dict,\\n        description=\\\"A dictionary of all raw key‑value pairs captured from the source string.\\\"\\n    )\\n\",\n",
      "  \"entrypoint_class_name\": \"Record\"\n",
      "}\n",
      "Successfully wrote code to c-1_record_base_model.py\n",
      "\n",
      "{\n",
      "  \"code_string\": \"from typing import List, Dict, Optional\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass LogEntry(BaseModel):\\n    \\\"\\\"\\\"A normalized representation of a log line.\\n    \\n    The model captures common elements observed across heterogeneous log formats,\\n    providing a unified schema for downstream processing.\\n    \\\"\\\"\\\"\\n    timestamp: Optional[str] = Field(\\n        None,\\n        description=\\\"Timestamp of the log entry in the form 'YYYY-MM-DD HH:MM:SS'. \\\"\\n                    \\\"Present when the source includes an explicit datetime component.\\\"\\n    )\\n    level: str = Field(\\n        ...,\\n        description=\\\"Log severity level, such as INFO, WARN, ERROR, etc. \\\"\\n                    \\\"This field is required because every sample contains a level indicator.\\\"\\n    )\\n    message: Optional[str] = Field(\\n        None,\\n        description=\\\"Human‑readable message describing the event, e.g., 'User login successful'. \\\"\\n                    \\\"May be absent when the log format focuses on key/value pairs only.\\\"\\n    )\\n    user: Optional[str] = Field(\\n        None,\\n        description=\\\"Username associated with the event when provided (e.g., 'Sam').\\\"\\n    )\\n    user_id: Optional[int] = Field(\\n        None,\\n        description=\\\"Numeric identifier of the user performing the action, extracted from a key like 'user_id'.\\\"\\n    )\\n    record_id: Optional[int] = Field(\\n        None,\\n        description=\\\"Generic numeric identifier present in some logs (e.g., 'id=1'). \\\"\\n                    \\\"Named generically to avoid conflating with user_id.\\\"\\n    )\\n\"\n",
      "  ,\n",
      "  \"entrypoint_class_name\": \"LogEntry\"\n",
      "}\n",
      "Successfully wrote code to c2_logentry_base_model.py\n",
      "\n",
      "{\n",
      "  \"code_string\": \"from typing import Optional\\nfrom pydantic import BaseModel, Field\\n\\nclass LogEntry(BaseModel):\\n    version: Optional[int] = Field(\\n        None,\\n        description=\\\"Version number extracted from key‑value metadata lines, e.g., 'version: 3'.\\\"\\n    )\\n    product: Optional[str] = Field(\\n        None,\\n        description=\\\"Product name from metadata, e.g., 'software'.\\\"\\n    )\\n    timestamp: Optional[str] = Field(\\n        None,\\n        description=\\\"Timestamp of the log event in ISO‑like format, e.g., '2026-01-30 14:22:01' or '[2026-01-31 17:11:22 +0000]'.\\\"\\n    )\\n    level: Optional[str] = Field(\\n        None,\\n        description=\\\"Log severity level such as 'INFO', 'DEBUG', etc.\\\"\\n    )\\n    message: Optional[str] = Field(\\n        None,\\n        description=\\\"Human‑readable log message content.\\\"\\n    )\\n    pid: Optional[int] = Field(\\n        None,\\n        description=\\\"Process identifier when present, e.g., '[7]'.\\\"\\n    )\\n    component: Optional[str] = Field(\\n        None,\\n        description=\\\"Application component or service name, e.g., 'swirl'.\\\"\\n    )\\n    source_file: Optional[str] = Field(\\n        None,\\n        description=\\\"Source file name where the log originated, e.g., 'saq_worker.py'.\\\"\\n    )\\n    source_line: Optional[int] = Field(\\n        None,\\n        description=\\\"Line number within the source file, e.g., 28.\\\"\\n    )\\n    client_ip: Optional[str] = Field(\\n        None,\\n        description=\\\"IP address of the client making the request, e.g., '127.0.0.1'.\\\"\\n    )\\n    client_port: Optional[int] = Field(\\n        None,\\n        description=\\\"Port number of the client, e.g., 56718.\\\"\\n    )\\n    request_method: Optional[str] = Field(\\n        None,\\n        description=\\\"HTTP method from the request line, e.g., 'GET'.\\\"\\n    )\\n    request_path: Optional[str] = Field(\\n        None,\\n        description=\\\"Path component of the HTTP request, e.g., '/health'.\\\"\\n    )\\n    http_version: Optional[str] = Field(\\n        None,\\n        description=\\\"HTTP protocol version from the request line, e.g., '1.1'.\\\"\\n    )\\n    status_code: Optional[int] = Field(\\n        None,\\n        description=\\\"HTTP response status code, e.g., 200.\\\"\\n    )\\n    response_bytes: Optional[int] = Field(\\n        None,\\n        description=\\\"Number of bytes in the HTTP response body, e.g., 16.\\\"\\n    )\\n    user_agent: Optional[str] = Field(\\n        None,\\n        description=\\\"User‑Agent string from the request, e.g., 'curl/8.14.1'.\\\"\\n    )\",\n",
      "  \"entrypoint_class_name\": \"LogEntry\"\n",
      "}\n",
      "Successfully wrote code to c0_logentry_base_model.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ModelResponseStructure(BaseModel):\n",
    "    code_string: str = Field(..., description=\"generated python code\")\n",
    "    entrypoint_class_name: str = Field(\n",
    "        ..., description=\"name of entrypoint base model class in the code generated\"\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_python_code(text):\n",
    "    \"\"\"\n",
    "    Extracts the Python code block from a string.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted source code or an empty string if not found.\n",
    "    \"\"\"\n",
    "    block_pattern = r\"```(?:python)?\\s*(.*?)\\s*```\"\n",
    "    match = re.search(block_pattern, text, re.DOTALL)\n",
    "\n",
    "    return match.group(1).strip() if match else \"\"\n",
    "\n",
    "\n",
    "for c_id, records in cluster_dict.items():\n",
    "    string_li = [r[\"raw\"] for r in records]\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": PYDANTIC_SYSTEM_PROMPT},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": PYDANTIC_USER_PROMPT.format(\n",
    "                samples=string_li,\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    buffer = []\n",
    "    response = await client.chat(\n",
    "        messages=messages,\n",
    "        stream=True,\n",
    "        temperature=0.0,\n",
    "        response_format=ModelResponseStructure,\n",
    "    )\n",
    "    async for chunk in response:\n",
    "        if chunk.choices and chunk.choices[0].delta.content:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            print(content, end=\"\", flush=True)\n",
    "            buffer.append(content)\n",
    "\n",
    "    resp = \"\".join(buffer)\n",
    "    resp: ModelResponseStructure = ModelResponseStructure(**json.loads(resp))\n",
    "\n",
    "    if not resp.code_string.startswith(\"```python\"):\n",
    "        resp.code_string = f\"```python\\n{resp.code_string}\\n```\"\n",
    "\n",
    "    code = extract_python_code(resp.code_string)\n",
    "\n",
    "    namespace = {}\n",
    "    exec(code, globals(), namespace)\n",
    "\n",
    "    # 3. Access the function from the namespace dictionary\n",
    "    cls = namespace.get(resp.entrypoint_class_name)\n",
    "    cls.model_rebuild(_types_namespace=namespace)\n",
    "    schema = cls.model_json_schema()\n",
    "\n",
    "    fname = f\"c{c_id}_{resp.entrypoint_class_name.lower()}_base_model.py\"\n",
    "    code = code.encode(\"ascii\", errors=\"ignore\").decode(\"ascii\")\n",
    "    with open(fname, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(code)\n",
    "        print(f\"\\nSuccessfully wrote code to {fname}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "877b059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example from `c1_order_base_model.py`\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Location(BaseModel):\n",
    "    \"\"\"Geographic location of the buyer.\n",
    "\n",
    "    The location is represented as a city and a twoletter US state abbreviation.\n",
    "    \"\"\"\n",
    "\n",
    "    city: str = Field(..., description=\"Name of the city where the buyer is located.\")\n",
    "    state: str = Field(\n",
    "        ..., description='Twoletter US state abbreviation (e.g., \"WA\", \"OH\").'\n",
    "    )\n",
    "\n",
    "\n",
    "class Order(BaseModel):\n",
    "    \"\"\"Representation of a single purchase order.\n",
    "\n",
    "    Each order includes an identifier, buyer information, optional location, the monetary total,\n",
    "    a list of purchased items, and an optional flag indicating whether a discount was applied.\n",
    "    \"\"\"\n",
    "\n",
    "    order_id: int = Field(..., description=\"Unique numeric identifier for the order.\")\n",
    "    buyer: str = Field(\n",
    "        ..., description=\"Full name of the buyer as it appears in the source data.\"\n",
    "    )\n",
    "    location: Optional[Location] = Field(\n",
    "        None,\n",
    "        description=\"Optional location object containing city and state. May be missing in some records.\",\n",
    "    )\n",
    "    total: float = Field(\n",
    "        ...,\n",
    "        description=\"Total amount of the order in US dollars. Dollar sign and commas are stripped during parsing.\",\n",
    "    )\n",
    "    items: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of item names purchased. The list may be empty if no items are recorded.\",\n",
    "    )\n",
    "    discount_applied: Optional[bool] = Field(\n",
    "        None,\n",
    "        description=\"Flag indicating whether a discount was applied to the order. True when a discount marker is present; otherwise False or omitted.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example `c2_logentry_base_model.py`\n",
    "\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class LogEntry(BaseModel):\n",
    "    \"\"\"A normalized representation of a log line.\n",
    "\n",
    "    The model captures common elements observed across heterogeneous log formats,\n",
    "    providing a unified schema for downstream processing.\n",
    "    \"\"\"\n",
    "\n",
    "    timestamp: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Timestamp of the log entry in the form 'YYYY-MM-DD HH:MM:SS'. \"\n",
    "        \"Present when the source includes an explicit datetime component.\",\n",
    "    )\n",
    "    level: str = Field(\n",
    "        ...,\n",
    "        description=\"Log severity level, such as INFO, WARN, ERROR, etc. \"\n",
    "        \"This field is required because every sample contains a level indicator.\",\n",
    "    )\n",
    "    message: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Humanreadable message describing the event, e.g., 'User login successful'. \"\n",
    "        \"May be absent when the log format focuses on key/value pairs only.\",\n",
    "    )\n",
    "    user: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Username associated with the event when provided (e.g., 'Sam').\",\n",
    "    )\n",
    "    user_id: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Numeric identifier of the user performing the action, extracted from a key like 'user_id'.\",\n",
    "    )\n",
    "    record_id: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Generic numeric identifier present in some logs (e.g., 'id=1'). \"\n",
    "        \"Named generically to avoid conflating with user_id.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a80c7b",
   "metadata": {},
   "source": [
    "## Langgraph Robustness and Stategraph "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dq-swirl (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
